
- [MPP-Qwen14B](#mpp-qwen14b)
  - [Introduction](#introduction)
  - [é™„å±é¡¹ç›®](#é™„å±é¡¹ç›®)
  - [æ‰€éœ€è®¡ç®—èµ„æº](#æ‰€éœ€è®¡ç®—èµ„æº)
  - [TODO LIST](#todo-list)
  - [Installation](#installation)
  - [Getting Started](#getting-started)
    - [æ¨¡å‹ä¸‹è½½](#æ¨¡å‹ä¸‹è½½)
  - [è®­ç»ƒ](#è®­ç»ƒ)
    - [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
    - [æ•°æ®tokensæ•°ç›®åˆ†æ](#æ•°æ®tokensæ•°ç›®åˆ†æ)
    - [è¿è¡Œtrain\_pipeline.pyè¿›è¡Œæµæ°´çº¿å¹¶è¡Œè®­ç»ƒ](#è¿è¡Œtrain_pipelinepyè¿›è¡Œæµæ°´çº¿å¹¶è¡Œè®­ç»ƒ)
  - [deepspeedæƒé‡è½¬æ¢ä¸ºpthæ–‡ä»¶](#deepspeedæƒé‡è½¬æ¢ä¸ºpthæ–‡ä»¶)
    - [é¢„è®­ç»ƒé˜¶æ®µ](#é¢„è®­ç»ƒé˜¶æ®µ)
    - [sfté˜¶æ®µ](#sfté˜¶æ®µ)
  - [æ¨ç†](#æ¨ç†)
    - [è¿è¡Œå‘½ä»¤è¡Œdemo](#è¿è¡Œå‘½ä»¤è¡Œdemo)
    - [è¿è¡Œgradio webui demo](#è¿è¡Œgradio-webui-demo)
  - [MPP-Qwen14Bå¯¹è¯ç¤ºä¾‹](#mpp-qwen14bå¯¹è¯ç¤ºä¾‹)
  - [Acknowledgement](#acknowledgement)
  - [License](#license)

ä¼¼ä¹è¢«çˆ±å¯å¯è€å¸ˆè½¬å‘äº†ğŸ¥¹ï¼Œæ„Ÿè°¢å¤§å®¶å…³æ³¨ï¼

MiniGPT4Qwenç›¸å…³å¯ä»¥è·³è½¬åˆ°ï¼š[MiniGPT4Qwen_README.md](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/MiniGPT4Qwen_README.md)
# MPP-Qwen14B
çŸ¥ä¹åšå®¢ï¼š[https://zhuanlan.zhihu.com/p/687106694](https://zhuanlan.zhihu.com/p/687106694)

**å·²æ”¯æŒMPP-Qwen-14Bæ¨¡å‹åœ¨2å¼ RTX4090 24GBä¸Šé¢„è®­ç»ƒå’Œ6å¼ RTX4090 24GBä¸Šsftçš„deepspeedæµæ°´çº¿å¹¶è¡Œè®­ç»ƒï¼**

![](./assets/framework2.png)
========
![](./assets/mpp-qwen-2.png)
======
![](./assets/mpp-qwen1.png)

## Introduction
å»å¹´11æœˆå‘å¸ƒçš„[LLaVA1.5](https://github.com/haotian-liu/LLaVA)ï¼Œç”¨å¯ä»¥æ¥å—çš„æ•°æ®é‡ï¼ˆ558K Pretrain + 665K SFTï¼‰ï¼Œä»¥Vicuna-v1.5-13Bä¸ºåŸºåº§ï¼Œå¾—åˆ°äº†éå¸¸å¥½çš„æ€§èƒ½ã€‚åç»­è¢«å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œå¹¿æ³›followã€‚

åœ¨è¯»è¿‡å…¶åœ¨githubä¸Šçš„READMEåå‘ç°ï¼Œ24GBçš„æ¶ˆè´¹çº§åˆ«æ˜¾å¡ï¼ˆRTX3090ã€RTX4090ç­‰ï¼‰ä»…å¯ä»¥å®Œæˆä»¥Vicuna-v1.5-7Bä¸ºåº•åº§çš„è®­ç»ƒï¼Œè€Œä¸”Openå‡ºçš„æ˜¯LoRAçš„é…ç½®ã€‚

**ä¸ºäº†ä¸è®©è´«ç©·é™åˆ¶æƒ³è±¡åŠ›**ï¼Œæ¥ç€MiniGPT4Qwen-14Bçš„deepspeedæµæ°´çº¿å¹¶è¡Œæ¡†æ¶ï¼Œæ¨å‡ºMPP-Qwen14Bï¼ˆMultimodal Pipeline Parallel-Qwen14Bï¼‰ï¼Œ**å…¨ç¨‹åœ¨RTX4090 24GBä¸Šå®Œæˆåªè®­ç»ƒlinearå±‚çš„Pretrainé˜¶æ®µå’ŒLLMå…¨å‚æ•°è®­ç»ƒçš„SFTé˜¶æ®µã€‚**

## é™„å±é¡¹ç›®
- çŸ¥ä¹åšå®¢ï¼š[MiniGPT4Qwen-14B](https://zhuanlan.zhihu.com/p/684462477)
- çŸ¥ä¹åšå®¢ï¼š[MiniGPT4Qwen](https://zhuanlan.zhihu.com/p/664612306)
- å¹²å‡€ã€çµæ´»çš„Trainerï¼šhttps://github.com/Coobiw/MiniGPT4Qwen/tree/master/lavis_trainer_cleaned
    - çŸ¥ä¹ï¼šhttps://zhuanlan.zhihu.com/p/670572461

- grad-checkpoint + amp tutorailsï¼šhttps://github.com/Coobiw/MiniGPT4Qwen/tree/master/amp_and_grad-checkpointing
    - çŸ¥ä¹ï¼šhttps://zhuanlan.zhihu.com/p/671165275?

- deepspeed tutorialsï¼šhttps://github.com/Coobiw/MiniGPT4Qwen/tree/master/deepspeed_tutorials
    - çŸ¥ä¹ï¼šhttps://zhuanlan.zhihu.com/p/673359684


## æ‰€éœ€è®¡ç®—èµ„æº
- MPP-Qwen14B Pretrainï¼š2å¼ RTX 4090 24GB
- MPP-Qwen14B SFTï¼š6å¼ RTX 4090 24GB

## TODO LIST
- [ ] æ”¯æŒmodel parallelismçš„æ¨ç†ï¼ˆå‚è€ƒ[llama2-accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory)ï¼‰
- [ ] å¼€æºsftæƒé‡ï¼ˆhuggingfaceæˆ–ç™¾åº¦ç½‘ç›˜ï¼‰
- [x] å¼€æºpretrainæƒé‡
- [x] å¼€æºå¤„ç†å¥½çš„pretrainå’Œsftçš„æ•°æ®é›†jsonæ–‡ä»¶
- [x] å¼€æºpretrainå’Œsftä»£ç å’Œconfig
- [x] æ”¯æŒdeepspeedçš„æµæ°´çº¿å¹¶è¡Œ

## Installation

```bash
conda create -n minigpt4qwen python=3.8
conda activate minigpt4qwen
pip install -e .
```

## Getting Started

### æ¨¡å‹ä¸‹è½½

> è¯·å°†æ¨¡å‹æƒé‡ä¸‹è½½åéƒ½æ”¾åœ¨ `cache/ckpt`ä¸‹

```bash
mkdir cache
cd cache
mkdir ckpt
mkdir dataset
```

1.ä¸‹è½½BLIP2çš„ç›¸å…³æƒé‡

(a) eva vit-g

[eva_vit_g.pth](https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/eva_vit_g.pth)

```bash
wget https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/eva_vit_g.pth
```

(b) bert-base-uncased

[huggingface](https://huggingface.co/bert-base-uncased/tree/main),ä¸‹è½½å¦‚ä¸‹çš„æ–‡ä»¶å³å¯

![image-20231026013454256](./assets/image-20231026013454256.png)

(c) blip2_pretrained_flant5xxl

[blip2_pretrained_flant5xxl.pth](https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xxl.pth)

```bash
wget https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xxl.pth
```

2.ä¸‹è½½Qwen-14B-Chatçš„æƒé‡

[Qwen-14B-chat huggingface](https://huggingface.co/Qwen/Qwen-14B-Chat)

3.è·å¾—pretrainåçš„checkpointï¼ˆoptionalï¼Œå¦‚æœä½ æƒ³ç›´æ¥åœ¨è¿™ä¸Šé¢åšsftçš„è¯ï¼‰

(å»ºè®®æ”¾å…¥ `lavis/output/pp_14b/pretrain`)

åœ¨æœ¬ä»“åº“çš„releaseé‡Œæ”¾æœ‰checkpointï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½

```bash
wget https://github.com/Coobiw/MiniGPT4Qwen/releases/download/MPP-Qwen14B_ckpt-and-data/ckpt-and-data.zip
unzip ckpt-and-data.zip
```

ç›®å½•ç»“æ„ï¼š

```bash
â”œâ”€â”€ cache
â”‚   â”œâ”€â”€ ckpt
â”‚   â”‚   â”œâ”€â”€ bert-base-uncased
â”‚   â”‚   â”œâ”€â”€ blip2
â”‚   â”‚   â”‚   â”œâ”€â”€ blip2_pretrained_flant5xxl.pth
â”‚   â”‚   â”œâ”€â”€ eva
â”‚   â”‚   â”‚   â”œâ”€â”€ eva_vit_g.pth
â”‚   â”‚   â”œâ”€â”€ Qwen-14B-chat
```


## è®­ç»ƒ

### æ•°æ®å‡†å¤‡

MPP-Qwen14Bä½¿ç”¨äº†LLaVAçš„Pretrainå’ŒæŒ‡ä»¤å¾®è°ƒçš„æ•°æ®é›†ï¼Œæ‰€ä»¥æ•´ä½“æ•°æ®è·å–æµç¨‹ä¸LLaVAä»“åº“è¯´æ˜çš„å¤§ä½“ä¸€è‡´ã€‚

é¢„è®­ç»ƒæ•°æ®ï¼š[558K subset of the LAION-CC-SBU dataset with BLIP captions](https://huggingface.co/datasets/liuhaotian/LLaVA-Pretrain)ï¼Œå»è¯¥huggingfaceé“¾æ¥ä¸‹è½½`images.zip`å’Œ`blip_laion_cc_sbu_558k.json`

æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼šä¸‹è½½cocoçš„train2017é‡Œçš„å›¾ç‰‡ï¼š
```bash
wget http://images.cocodataset.org/zips/train2017.zip
unzip train2017.zip
```

MPP-Qwen14B formatçš„æ ‡æ³¨jsonæ–‡ä»¶ï¼šåœ¨æœ¬ä»“åº“çš„releaseä¸­([https://github.com/Coobiw/MiniGPT4Qwen/releases/tag/MPP-Qwen14B_ckpt-and-data](https://github.com/Coobiw/MiniGPT4Qwen/releases/tag/MPP-Qwen14B_ckpt-and-data)):
```bash
wget https://github.com/Coobiw/MiniGPT4Qwen/releases/download/MPP-Qwen14B_ckpt-and-data/ckpt-and-data.zip
unzip ckpt-and-data.zip
```

ç„¶åæŒ‰ç…§ä¸‹é¢çš„ç›®å½•ç»“æ„ç»„ç»‡æ–‡ä»¶

æœ€åéœ€è¦å°†æ•°æ®é›†æ”¾å…¥ `./cache/dataset`ä¸­ï¼Œç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```bash
â”œâ”€â”€ cache
â”‚   â””â”€â”€ dataset
â”‚       â”œâ”€â”€ llava_pretrain
â”‚   â”‚   â”‚   â”œâ”€â”€ blip_laion_cc_sbu_558k
â”‚   â”‚   â”‚   |   â”œâ”€â”€ images
â”‚   â”‚   â”‚   |   â”œâ”€â”€ llava_pretrain_minigpt4qwen_format.json
â”‚       â”œâ”€â”€ llava_instuct
â”‚   â”‚   â”‚   â”œâ”€â”€ coco
â”‚   â”‚   â”‚   |   â”œâ”€â”€ train2017
â”‚   â”‚   â”‚   â”œâ”€â”€ llava_instruction_100k.json
```

### æ•°æ®tokensæ•°ç›®åˆ†æ
```bash
python tokenize_analysis.py
```

![](./vis/Pretrain_token_distribution.png)
======
![](./vis/SFT_token_distribution.png)

æ ¹æ®æ­¤ï¼Œä¼šåœ¨trainçš„é…ç½®æ–‡ä»¶ä¸­ï¼Œpretrainå’Œsftçš„`max_txt_len`åˆ†åˆ«è®¾ç½®ä¸º256å’Œ512

### è¿è¡Œtrain_pipeline.pyè¿›è¡Œæµæ°´çº¿å¹¶è¡Œè®­ç»ƒ

Pretrainï¼š

```bash
python -m torch.distributed.run --nproc_per_node=2 train_pipeline.py --cfg-path lavis/projects/pp_qwen14b/pretrain_pp.yaml --num-stages 2
```

SFTï¼š

```bash
python -m torch.distributed.run --nproc_per_node=6 train_pipeline.py --cfg-path lavis/projects/pp_qwen14b/sft_100k_pp.yaml --num-stages 6
```

## deepspeedæƒé‡è½¬æ¢ä¸ºpthæ–‡ä»¶

### é¢„è®­ç»ƒé˜¶æ®µ

ï¼ˆä»…è½¬æ¢linear projectionå±‚ï¼‰

```bash
python pipe_proj2pth.py --ckpt-dir lavis/output/pp_14b/pretrain/global_stepxxx
```

è½¬æ¢åï¼Œæ¨¡å‹æ–‡ä»¶ä¼šå­˜å‚¨åœ¨`ckpt_dir`åº•ä¸‹ï¼Œåä¸º`model.pth`

### sfté˜¶æ®µ

ï¼ˆéœ€è¦è½¬æ¢projectionå±‚å’Œæ‰€æœ‰LLMçš„å‚æ•°ï¼‰

```bash
python pipemodel2pth.py --ckpt-dir lavis/output/pp_14b/sft/global_stepxxx
```

è½¬æ¢åï¼Œæ¨¡å‹æ–‡ä»¶ä¼šå­˜å‚¨åœ¨`ckpt_dir`åº•ä¸‹ï¼Œåä¸º`unfreeze_llm_model.pth`

## æ¨ç†

### è¿è¡Œå‘½ä»¤è¡Œdemo

```bash
python cli_demo.py -c xxxxxx --model-type qwen14b_chat --cpu-only # å¦‚æœæ˜¾å­˜è¶³å¤Ÿ(>30GB)å¯ä»¥ä¸è¦--cpu-only
```

è¿è¡Œåéœ€è¦è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼Œè¾“å…¥åè¿›å…¥å¯¹è¯

å¸¸è§æ“ä½œï¼š

> :help æŸ¥çœ‹help
>
> :clear æ¸…ç©ºå½“å‰å‘½ä»¤è¡Œ
>
> :clh æ¸…ç©ºå¯¹è¯å†å²ï¼ˆä½†å›¾åƒè¾“å…¥ä¸ä¼šæ›´æ”¹ï¼‰
>
> :his æŸ¥çœ‹å¯¹è¯å†å²
>
> :img æŸ¥çœ‹è¾“å…¥çš„å›¾åƒè·¯å¾„

### è¿è¡Œgradio webui demo
```bash
python webui_demo.py -c xxxxxx --model-type qwen14b_chat --cpu-only # å¦‚æœæ˜¾å­˜è¶³å¤Ÿ(>30GB)å¯ä»¥ä¸è¦--cpu-only
```

## MPP-Qwen14Bå¯¹è¯ç¤ºä¾‹
========
![](./assets/mpp-qwen1.png)
======
![](./assets/mpp-qwen-2.png)

## Acknowledgement

- [Lavis](https://github.com/salesforce/LAVIS) æœ¬ä»“åº“æ˜¯åŸºäºlavisè¿›è¡Œæ„å»ºçš„ï¼Œä¸”ä½¿ç”¨äº†å…¶ä¸­BLIP2çš„ViTå’ŒQ-former
- [QwenLM](https://github.com/QwenLM/Qwen) æœ¬ä»“åº“çš„è¯­è¨€æ¨¡å‹é‡‡ç”¨Qwen-14B-Chat
- [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸ‘
- [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples) ğŸ‘ğŸ‘
- [LLaVA](https://github.com/haotian-liu/LLaVA) å‚ç…§å…¶è®­ç»ƒèŒƒå¼ï¼Œä½¿ç”¨äº†å…¶é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®

## License

- æœ¬ä»“åº“çš„è®¸å¤šä»£ç æ˜¯åŸºäº[Lavis](https://github.com/salesforce/LAVIS) çš„ï¼Œå…¶é‡‡ç”¨ [BSD 3-Clause License](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/LICENSE_Lavis.md).
- æœ¬ä»“åº“é‡‡ç”¨Qwen-7B-Chatï¼Œæ”¯æŒå•†ç”¨å’Œç§‘ç ”ã€å¼€å‘ç”¨é€”ï¼Œå…¶Licenseä¸º[LICENSE](https://github.com/QwenLM/Qwen/blob/main/LICENSE)
