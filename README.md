<div align="center">
    <img src="./assets/MPPQwen/logo.webp" alt="MPP-Qwen-Next logo" width="300" />
</div>

- [MPP-Qwen-Next: Multimodal Pipeline Parallel based on QwenLM](#mpp-qwen-next-multimodal-pipeline-parallel-based-on-qwenlm)
  - [News](#news)
  - [Framework](#framework)
  - [Features](#features)
    - [å›¾åƒ-å•è½®é—®ç­”](#å›¾åƒ-å•è½®é—®ç­”)
    - [å›¾åƒ-å¤šè½®å¯¹è¯](#å›¾åƒ-å¤šè½®å¯¹è¯)
    - [è§†é¢‘-å¯¹è¯](#è§†é¢‘-å¯¹è¯)
    - [å¤šå›¾-å¯¹è¯ï¼ˆæœªç»è¿‡å¤šå›¾sftï¼Œè§†é¢‘sftåæ¶Œç°è¯¥èƒ½åŠ›ï¼‰](#å¤šå›¾-å¯¹è¯æœªç»è¿‡å¤šå›¾sftè§†é¢‘sftåæ¶Œç°è¯¥èƒ½åŠ›)
  - [TODO LIST](#todo-list)
  - [Installation](#installation)
  - [Weight\&Data Preparation](#weightdata-preparation)
  - [æ¨ç†](#æ¨ç†)
  - [æµæ°´çº¿å¹¶è¡Œè®­ç»ƒ(PP+DP)](#æµæ°´çº¿å¹¶è¡Œè®­ç»ƒppdp)
  - [äºŒé˜¶æ®µè®­ç»ƒlossæ›²çº¿å‚è€ƒ](#äºŒé˜¶æ®µè®­ç»ƒlossæ›²çº¿å‚è€ƒ)
  - [Custom Data Format(å¦‚æœä½ æƒ³continue training)](#custom-data-formatå¦‚æœä½ æƒ³continue-training)
  - [Acknowledgement](#acknowledgement)
  - [License](#license)
  - [Star History](#star-history)



# MPP-Qwen-Next: Multimodal Pipeline Parallel based on QwenLM

https://github.com/Coobiw/MiniGPT4Qwen/assets/48615375/963416dd-fd97-4680-b7ac-fa4a14beaaae

<video controls>
  <source src="https://github.com/Coobiw/MiniGPT4Qwen/assets/48615375/963416dd-fd97-4680-b7ac-fa4a14beaaae" type="video/mp4">
  Your browser does not support the video tag.
</video>

https://github.com/Coobiw/MiniGPT4Qwen/assets/48615375/0e7c33f6-33d3-478a-ab0e-ecc116aeec78

<video controls>
  <source src="https://github.com/Coobiw/MiniGPT4Qwen/assets/48615375/0e7c33f6-33d3-478a-ab0e-ecc116aeec78" type="video/mp4">
  Your browser does not support the video tag.
</video>

## News
- [2024/6] ğŸ”¥ å¼€æºMPP-Qwen-Nextçš„sftæƒé‡(15GB) [modelscopeé“¾æ¥](https://www.modelscope.cn/models/Coobiw/MPP-Qwen-Next) [ç™¾åº¦ç½‘ç›˜é“¾æ¥](https://pan.baidu.com/s/15rfwuCfM_sdViWQJv1mZmg?pwd=baka)
- [2024/6] ğŸ”¥ **MPP-Qwen-Next**: åŠ å…¥llavaçš„å¤šè½®å¯¹è¯sftæ•°æ®ä»¥åŠvideochatgptçš„100k sftæ•°æ®ï¼Œ**æ”¯æŒå›¾åƒå¤šè½®å¯¹è¯ï¼Œè§†é¢‘å¯¹è¯ï¼Œå¹¶æ¶Œç°å‡ºå¤šå›¾å¯¹è¯èƒ½åŠ›** [çŸ¥ä¹åšå®¢](https://zhuanlan.zhihu.com/p/703597348)
- [2024/5] ğŸ”¥ ä»£ç æ”¯æŒå¤šè½®å¯¹è¯sftã€è§†é¢‘sftã€å¤šå›¾sft
- [2024/4] ğŸ”¥ æ”¯æŒå¤šå¡æ¨ç†ï¼Œä¿®æ­£chat templateä»¥è·å¾—æ›´å¥½çš„å¯¹è¯æ•ˆæœ [çŸ¥ä¹åšå®¢](https://zhuanlan.zhihu.com/p/698549757)
- [2024/3] ğŸ”¥ **MPPQwen-14B**: Extend MiniGPT4Qwen-14B to MPP-Qwen14B(Multimodal Pipeline Parallel). æ•°æ®å’Œè®­ç»ƒèŒƒå¼å‚ç…§LLaVAï¼ˆpretrain + sft)ï¼ŒæŒ‡ä»¤å¾®è°ƒæ—¶æ‰“å¼€LLMã€‚**å…¨éƒ¨è®­ç»ƒè¿‡ç¨‹åœ¨6å¼ RTX4090ä¸Šå®Œæˆ** [README&Tutorial](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/MPPQwen14B_README.md)ï¼› [çŸ¥ä¹åšå®¢](https://zhuanlan.zhihu.com/p/687106694)
- [2024/2] ğŸ”¥ **MiniGPT4Qwen-14B**: Scaling Up MiniGPT4Qwen to 14B. **ä½¿ç”¨DeepSpeed Pipeline Parallelè®©å…¨è¿‡ç¨‹ä»…ä½¿ç”¨2å¼ 4090æ˜¾å¡** [README&Tutorial](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/MiniGPT4Qwen_README.md)ï¼› [çŸ¥ä¹åšå®¢](https://zhuanlan.zhihu.com/p/684462477)
- [2023/10] ğŸ”¥ **MiniGPT4Qwen**ï¼šé‡‡ç”¨18.8kçš„é«˜è´¨é‡åŒè¯­æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼Œå¾—åˆ°**å•é˜¶æ®µè®­ç»ƒçš„ä¸ªäººç‰ˆåŒè¯­MLLM** [README&Tutorial](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/MiniGPT4Qwen_README.md)ï¼› [çŸ¥ä¹åšå®¢](https://zhuanlan.zhihu.com/p/664612306)

## Framework

![](./assets/MPPQwen/framework.png)

## Features

### å›¾åƒ-å•è½®é—®ç­”
![](assets/MPPQwen/pic1.jpg)

### å›¾åƒ-å¤šè½®å¯¹è¯
![](assets/MPPQwen/pic2.jpg)

### è§†é¢‘-å¯¹è¯
![](assets/MPPQwen/pic3.jpg)

### å¤šå›¾-å¯¹è¯ï¼ˆæœªç»è¿‡å¤šå›¾sftï¼Œè§†é¢‘sftåæ¶Œç°è¯¥èƒ½åŠ›ï¼‰
---
æ— è§†é¢‘sftçš„MPP-14Bæ¨¡å‹å¤šå›¾å¯¹è¯ï¼ˆçœ‹ä¼¼å›ç­”ï¼Œå®é™…å•¥éƒ½æ²¡è¯´ï¼‰ï¼š
![](assets/MPPQwen/pic4.jpg)

---
è§†é¢‘sftåçš„MPPQwen-8Bæ¨¡å‹ï¼ˆå…·å¤‡æ¯”è¾ƒä¸åŒå›¾åƒçš„èƒ½åŠ›ï¼‰ï¼š
![](assets/MPPQwen/pic5.jpg)


## TODO LIST
- [ ] åŠ å…¥huggingface-transformerså®ç°ï¼Œå¹¶pushåˆ°huggingface
- [x] å¼€æºsftæƒé‡ï¼ˆmodelscope & ç™¾åº¦ç½‘ç›˜ï¼‰
- [x] æ”¯æŒå•å›¾æ¨ç†ã€å¤šå›¾æ¨ç†ã€è§†é¢‘æ¨ç†
- [x] æ”¯æŒmodel parallelismçš„æ¨ç†ï¼ˆä½¿ç”¨äº†transformersçš„`device_map="auto"`ï¼‰
- [x] å¼€æºpretrainæƒé‡
- [x] å¼€æºå¤„ç†å¥½çš„pretrainå’Œsftçš„æ•°æ®é›†jsonæ–‡ä»¶
- [x] æ”¯æŒå¤šè½®å¯¹è¯ã€å¤šå›¾sftã€è§†é¢‘sft
- [x] æ”¯æŒdeepspeedçš„æµæ°´çº¿å¹¶è¡Œ

## Installation

```bash
conda create -n minigpt4qwen python=3.8 && conda activate minigpt4qwen
pip install -e .
```

## Weight&Data Preparation
è¯·æ”¾åœ¨`cache`ç›®å½•ä¸­ï¼Œç»“æ„å¦‚ä¸‹
![](assets/MPPQwen/pic6.jpg)

æ¨¡å‹æƒé‡è¯·å‚ç…§ï¼š[WEIGHT.md](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/WEIGHT.md)

è®­ç»ƒæ•°æ®è¯·å‚ç…§ï¼š[DATA.md](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/DATA.md)

## æ¨ç†
è¯·å…ˆæŒ‰ç…§[WEIGHT.md](https://github.com/Coobiw/MiniGPT4Qwen/blob/master/WEIGHT.md)é…ç½®å¥½æƒé‡

å¹¶åœ¨ä»¥ä¸‹é“¾æ¥ä¸­äºŒé€‰ä¸€ï¼Œä¸‹è½½sftåçš„æ¨¡å‹æƒé‡ï¼ˆ15GBï¼‰ï¼š
- [modelscopeé“¾æ¥](https://www.modelscope.cn/models/Coobiw/MPP-Qwen-Next)
- [ç™¾åº¦ç½‘ç›˜é“¾æ¥](https://pan.baidu.com/s/15rfwuCfM_sdViWQJv1mZmg?pwd=baka)
### è¿è¡Œå‘½ä»¤è¡Œdemo

**Single-GPU Inference**

```bash
python cli_demo.py --model-type qwen7b_chat -c lavis/output/pp_7b_video/sft_video/global_step2005/unfreeze_llm_model.pth
```



**MultiGPU(llmä½¿ç”¨`device_map="auto"åŠ è½½`ï¼Œå¯ä»¥å¤šå¡åŠ è½½LLMéƒ¨åˆ†æ¨¡å‹ï¼š**

```bash
python cli_demo.py --model-type qwen7b_chat -c lavis/output/pp_7b_video/sft_video/global_step2005/unfreeze_llm_model.pth --llm_device_map "auto"
```


**CPUï¼ˆé€Ÿåº¦æ…¢ï¼‰:**

```bash
python cli_demo.py--model-type qwen7b_chat -c lavis/output/pp_7b_video/sft_video/global_step2005/unfreeze_llm_model.pth --cpu-only # å¦‚æœæ˜¾å­˜è¶³å¤Ÿ(>=20GB)å¯ä»¥ä¸è¦--cpu-only
```

è¿è¡Œåéœ€è¦è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼Œå¯ä»¥è¾“å…¥å¤šå¼ å›¾ç‰‡ï¼Œç”¨`:f`ç»“æŸå›¾ç‰‡è·¯å¾„è¾“å…¥åè¿›å…¥å¯¹è¯

å¸¸è§æ“ä½œï¼š

> :help æŸ¥çœ‹help
>
> :clear æ¸…ç©ºå½“å‰å‘½ä»¤è¡Œ
>
> :clh æ¸…ç©ºå¯¹è¯å†å²ï¼ˆä½†å›¾åƒè¾“å…¥ä¸ä¼šæ›´æ”¹ï¼‰
>
> :his æŸ¥çœ‹å¯¹è¯å†å²
>
> :img æŸ¥çœ‹è¾“å…¥çš„å›¾åƒè·¯å¾„

### è¿è¡Œgradio webui demo

**Single-GPU Inference**

```bash
python webui_demo.py --model-type qwen7b_chat -c lavis/output/pp_7b_video/sft_video/global_step2005/unfreeze_llm_model.pth
```



**MultiGPU(llmä½¿ç”¨`device_map="auto"åŠ è½½`**

```bash
python webui_demo.py --model-type qwen7b_chat -c lavis/output/pp_7b_video/sft_video/global_step2005/unfreeze_llm_model.pth --llm_device_map "auto"
```



**CPUï¼š**

```bash
python webui_demo.py --model-type qwen7b_chat -c lavis/output/pp_7b_video/sft_video/global_step2005/unfreeze_llm_model.pth --cpu-only # å¦‚æœæ˜¾å­˜è¶³å¤Ÿ(>=20GB)å¯ä»¥ä¸è¦--cpu-only
```

## æµæ°´çº¿å¹¶è¡Œè®­ç»ƒ(PP+DP)
ä¸‹é¢ä¸º8å¡3090è¿è¡ŒæŒ‡ä»¤:

### Pretrain
> nproc_per_node: 8
> dp: 4
> pp: 2
> nproc_per_node = pp * dp

```bash
python -m torch.distributed.run --nproc_per_node=8 train_pipeline.py --cfg-path lavis/projects/pp_qwen7b_video/pretrain.yaml --num-stages 2
```

### SFT
> nproc_per_node: 8
> dp: 1
> pp: 8
> nproc_per_node = pp * dp

```bash
python -m torch.distributed.run --nproc_per_node=8 train_pipeline.py --cfg-path lavis/projects/pp_qwen7b_video/sft.yaml --num-stages 8
```

### pipeline parallelçš„æƒé‡è½¬æ¢ä¸ºpthæ–‡ä»¶

#### é¢„è®­ç»ƒé˜¶æ®µ:

ï¼ˆä»…è½¬æ¢linear projectionå±‚ï¼‰

```bash
python pipe_proj2pth.py --ckpt-dir lavis/output/pp_7b_video/pretrain/global_step2181
```

è½¬æ¢åï¼Œæ¨¡å‹æ–‡ä»¶ä¼šå­˜å‚¨åœ¨`ckpt_dir`åº•ä¸‹ï¼Œåä¸º`model.pth`

#### sfté˜¶æ®µ

ï¼ˆéœ€è¦è½¬æ¢projectionå±‚å’Œæ‰€æœ‰LLMçš„å‚æ•°ï¼‰

```bash
python pipemodel2pth.py --ckpt-dir lavis/output/pp_7b_video/sft_video/global_step2005
```

è½¬æ¢åï¼Œæ¨¡å‹æ–‡ä»¶ä¼šå­˜å‚¨åœ¨`ckpt_dir`åº•ä¸‹ï¼Œåä¸º`unfreeze_llm_model.pth`

## äºŒé˜¶æ®µè®­ç»ƒlossæ›²çº¿å‚è€ƒ
---

pretrainï¼š
![](./assets/MPPQwen/curve1.jpg)

---
sft:
![](./assets/MPPQwen/curve2.jpg)

## Custom Data Format(å¦‚æœä½ æƒ³continue training)
å¤„ç†å‡½æ•°å¯ä»¥å‚è€ƒ: [https://github.com/Coobiw/MiniGPT4Qwen/releases/download/MPP-Qwen-Next_ckpt-and-data/ckpt-and-data.zip](https://github.com/Coobiw/MiniGPT4Qwen/releases/download/MPP-Qwen-Next_ckpt-and-data/ckpt-and-data.zip)ä¸­ï¼Œllava_instuctå’Œvideochatgptç›®å½•é‡Œçš„`analysis.py`è„šæœ¬

***P.S.: å¦‚æœè·¯å¾„ç»å¸¸å‡ºé”™ï¼Œå¯ä»¥æŠŠæ‰€æœ‰è·¯å¾„éƒ½æ”¹æˆç»å¯¹è·¯å¾„ï¼ˆåŒ…æ‹¬dataset configsï¼‰***
### å›¾åƒæŒ‡ä»¤å¾®è°ƒæ•°æ®æ ¼å¼
å•è½®(instructionå’Œoutputä¸º`str`)ï¼š
```json
[
    {
        "image": "000000215677.jpg",
        "instruction": "<Img><ImageHere></Img> {question}",
        "output": "{answer}"
    },
]
```

å¤šè½®(instructionå’Œoutputä¸ºç­‰é•¿çš„`list`)ï¼š
```json
{
        "image": "000000479443.jpg",
        "instruction": [
            "<Img><ImageHere></Img> {question1}",
            "{question2}",
            "..."
        ],
        "output": [
            "{answer1}",
            "{answer2}",
            "..."
        ]
    },
```

### è§†é¢‘æŒ‡ä»¤å¾®è°ƒæ•°æ®æ ¼å¼
```json
[
    {
        "video": "v_k_ZXmr8pmrs.mkv",
        "instruction": "<Img><ImageHere></Img> {question}",
        "output": "{answer}"
    }
]
```

## Acknowledgement

- [Lavis](https://github.com/salesforce/LAVIS) æœ¬ä»“åº“æ˜¯åŸºäºlavisè¿›è¡Œæ„å»ºçš„ï¼Œä¸”ä½¿ç”¨äº†å…¶ä¸­BLIP2çš„ViTå’ŒQ-former
- [QwenLM](https://github.com/QwenLM/Qwen) æœ¬ä»“åº“çš„è¯­è¨€æ¨¡å‹é‡‡ç”¨Qwen7B-Chat
- [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸ‘
- [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples) ğŸ‘ğŸ‘
- [LLaVA](https://github.com/haotian-liu/LLaVA) å‚ç…§å…¶è®­ç»ƒèŒƒå¼ï¼Œä½¿ç”¨äº†å…¶é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®
- [VideoChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) ä½¿ç”¨å…¶è§†é¢‘sftçš„100kæ•°æ®
- [Video-LLaVA](https://github.com/PKU-YuanGroup/Video-LLaVA) æä¾›videochatgptè§†é¢‘æ•°æ®çš„ç™¾åº¦ç½‘ç›˜ä¸‹è½½é“¾æ¥

## License

- æœ¬ä»“åº“çš„è®¸å¤šä»£ç æ˜¯åŸºäº[Lavis](https://github.com/salesforce/LAVIS) çš„ï¼Œå…¶é‡‡ç”¨ [BSD 3-Clause License](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/LICENSE_Lavis.md).
- æœ¬ä»“åº“é‡‡ç”¨Qwen-7B-Chatï¼Œæ”¯æŒå•†ç”¨å’Œç§‘ç ”ã€å¼€å‘ç”¨é€”ï¼Œå…¶Licenseä¸º[LICENSE](https://github.com/QwenLM/Qwen/blob/main/LICENSE)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Coobiw/MPP-LLaVA&type=Date)](https://star-history.com/#Coobiw/MPP-LLaVA&Date)
